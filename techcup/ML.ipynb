{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "96249bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for processing\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# for scoring\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# for modeling\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a7c49b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = (\n",
    "    'athletics',\n",
    "    'autosport',\n",
    "    'basketball',\n",
    "    'boardgames',\n",
    "    'esport',\n",
    "    'extreme',\n",
    "    'football',\n",
    "    'hockey',\n",
    "    'martial_arts',\n",
    "    'motosport',\n",
    "    'tennis',\n",
    "    'volleyball',\n",
    "    'winter_sport',\n",
    ")\n",
    "\n",
    "TRAIN_CSV = '~/Downloads/train.csv'\n",
    "TEST_CSV = '~/Downloads/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78000807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oid</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>749208109</td>\n",
       "      <td>СПОЧНО СООБЩЕСТВО ПРОДАЕТСЯ ЗА 1300Р ЗА ПОКУПК...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>452466036</td>\n",
       "      <td>Естественное восстановление после тяжелой трен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>161038103</td>\n",
       "      <td>Тема нарядов продолжается Одна из британских ж...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>663621910</td>\n",
       "      <td>Привет Избранный. Ты спрашиваешь себя ЧТО здес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>566255305</td>\n",
       "      <td>КОРОЛЬ ПЯТИСОТНИКОВ В ДЕЛЕ Андрей Рублев успеш...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26255</th>\n",
       "      <td>169728316</td>\n",
       "      <td>Выиграй коллекционный пазл по Wortokenoid of W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26256</th>\n",
       "      <td>279369911</td>\n",
       "      <td>Волейбол от первого лица Егора Пупынина переко...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26257</th>\n",
       "      <td>600699419</td>\n",
       "      <td>Вы были когда нибудь на свидании где вам задав...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26258</th>\n",
       "      <td>560223506</td>\n",
       "      <td>ТОП 20 самых эффективных общефизических упражн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26259</th>\n",
       "      <td>724673712</td>\n",
       "      <td>Присылайте ваши беговые фото в комментарии к э...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26260 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             oid                                               text\n",
       "0      749208109  СПОЧНО СООБЩЕСТВО ПРОДАЕТСЯ ЗА 1300Р ЗА ПОКУПК...\n",
       "1      452466036  Естественное восстановление после тяжелой трен...\n",
       "2      161038103  Тема нарядов продолжается Одна из британских ж...\n",
       "3      663621910  Привет Избранный. Ты спрашиваешь себя ЧТО здес...\n",
       "4      566255305  КОРОЛЬ ПЯТИСОТНИКОВ В ДЕЛЕ Андрей Рублев успеш...\n",
       "...          ...                                                ...\n",
       "26255  169728316  Выиграй коллекционный пазл по Wortokenoid of W...\n",
       "26256  279369911  Волейбол от первого лица Егора Пупынина переко...\n",
       "26257  600699419  Вы были когда нибудь на свидании где вам задав...\n",
       "26258  560223506  ТОП 20 самых эффективных общефизических упражн...\n",
       "26259  724673712  Присылайте ваши беговые фото в комментарии к э...\n",
       "\n",
       "[26260 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(TEST_CSV)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d60647f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oid</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>365271984</td>\n",
       "      <td>winter_sport</td>\n",
       "      <td>Волшебные фото Виктория Поплавская ЕвгенияМедв...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>503385563</td>\n",
       "      <td>extreme</td>\n",
       "      <td>Возвращение в подземелье Треша 33 Эйфория тупо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146016084</td>\n",
       "      <td>football</td>\n",
       "      <td>Лучшие чешские вратари – Доминик Доминатор Гаш...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>933865449</td>\n",
       "      <td>boardgames</td>\n",
       "      <td>Rtokenoid Warhammer40k валрак решил нас подкор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>713550145</td>\n",
       "      <td>hockey</td>\n",
       "      <td>Шестеркин затаскивает Рейнджерс в финал Восточ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38735</th>\n",
       "      <td>910636962</td>\n",
       "      <td>autosport</td>\n",
       "      <td>8 битная буря снова накрыла пикселями автомоби...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38736</th>\n",
       "      <td>669736851</td>\n",
       "      <td>autosport</td>\n",
       "      <td>Ира Сидоркова объясняет как сказалась на ее ма...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38737</th>\n",
       "      <td>558919241</td>\n",
       "      <td>tennis</td>\n",
       "      <td>24 я ракетка мира хорват Марин Чилич обыграл и...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38738</th>\n",
       "      <td>776944963</td>\n",
       "      <td>volleyball</td>\n",
       "      <td>Стал известен календарь мужской сборной России...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38739</th>\n",
       "      <td>577334983</td>\n",
       "      <td>hockey</td>\n",
       "      <td>Первенство ВХЛ. Первый этап Динамо Алтай Бн ЦС...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38740 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             oid      category  \\\n",
       "0      365271984  winter_sport   \n",
       "1      503385563       extreme   \n",
       "2      146016084      football   \n",
       "3      933865449    boardgames   \n",
       "4      713550145        hockey   \n",
       "...          ...           ...   \n",
       "38735  910636962     autosport   \n",
       "38736  669736851     autosport   \n",
       "38737  558919241        tennis   \n",
       "38738  776944963    volleyball   \n",
       "38739  577334983        hockey   \n",
       "\n",
       "                                                    text  \n",
       "0      Волшебные фото Виктория Поплавская ЕвгенияМедв...  \n",
       "1      Возвращение в подземелье Треша 33 Эйфория тупо...  \n",
       "2      Лучшие чешские вратари – Доминик Доминатор Гаш...  \n",
       "3      Rtokenoid Warhammer40k валрак решил нас подкор...  \n",
       "4      Шестеркин затаскивает Рейнджерс в финал Восточ...  \n",
       "...                                                  ...  \n",
       "38735  8 битная буря снова накрыла пикселями автомоби...  \n",
       "38736  Ира Сидоркова объясняет как сказалась на ее ма...  \n",
       "38737  24 я ракетка мира хорват Марин Чилич обыграл и...  \n",
       "38738  Стал известен календарь мужской сборной России...  \n",
       "38739  Первенство ВХЛ. Первый этап Динамо Алтай Бн ЦС...  \n",
       "\n",
       "[38740 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(TRAIN_CSV)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e52606e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7        Какой т3 игрок на данный момент перспективнее ...\n",
       "14       Гвардиола об 1 0 с Атлетико Очень равный матч ...\n",
       "21       Сегодня подведем итоги трех конкурсов на одном...\n",
       "27       Ровно шесть лет назад s1mptokenoid присоединил...\n",
       "40       Btokenoid на подкасте EsportsDotokenoid Я нико...\n",
       "                               ...                        \n",
       "38695    Барса даст Левандовскому двухлетний или трехле...\n",
       "38697    ️АЛЕКСАНДР КОКОРИН ПРОПУСТИТ МАТЧ СО СПЕЦИЕЙ И...\n",
       "38707    В группе один Администратор Добавляй в друзья ...\n",
       "38717    Счастливчики которые уносят Кассадина 33 За пр...\n",
       "38732    etokenoid Я был самым большим фанатом shrotoke...\n",
       "Name: text, Length: 2990, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text'][train_data['category'] == 'esport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "93576c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oid</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>300500058</td>\n",
       "      <td>martial_arts</td>\n",
       "      <td>Как выглядел мир когда последний раз дрался Ди...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>652133165</td>\n",
       "      <td>martial_arts</td>\n",
       "      <td>Обувная ложка меч Kessak подарок для настоящег...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>545572382</td>\n",
       "      <td>martial_arts</td>\n",
       "      <td>Как заменить привычные чипсы? Отведайте сушки ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>827524142</td>\n",
       "      <td>martial_arts</td>\n",
       "      <td>Меня просто спровоцировали а те кто пишет в мо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>102339046</td>\n",
       "      <td>martial_arts</td>\n",
       "      <td>AMC FNG Амиржанов Гаджимурад Денисов Сергей 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38665</th>\n",
       "      <td>352307844</td>\n",
       "      <td>martial_arts</td>\n",
       "      <td>Они опять в Таиланде Кто помнит предыдущие фот...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38683</th>\n",
       "      <td>114699964</td>\n",
       "      <td>martial_arts</td>\n",
       "      <td>Дана Уайт сообщил когда и с кем будет драться ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38689</th>\n",
       "      <td>271219366</td>\n",
       "      <td>martial_arts</td>\n",
       "      <td>Генри Сехудо считает что Хамзат Чимаев эмоцион...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38691</th>\n",
       "      <td>545572382</td>\n",
       "      <td>martial_arts</td>\n",
       "      <td>Детский набор для творчества с мольбертом 176 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38728</th>\n",
       "      <td>642200097</td>\n",
       "      <td>martial_arts</td>\n",
       "      <td>️Рамазан Гасанов 8 0 побеждает Насимжона Шарип...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3050 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             oid      category  \\\n",
       "24     300500058  martial_arts   \n",
       "55     652133165  martial_arts   \n",
       "97     545572382  martial_arts   \n",
       "102    827524142  martial_arts   \n",
       "104    102339046  martial_arts   \n",
       "...          ...           ...   \n",
       "38665  352307844  martial_arts   \n",
       "38683  114699964  martial_arts   \n",
       "38689  271219366  martial_arts   \n",
       "38691  545572382  martial_arts   \n",
       "38728  642200097  martial_arts   \n",
       "\n",
       "                                                    text  \n",
       "24     Как выглядел мир когда последний раз дрался Ди...  \n",
       "55     Обувная ложка меч Kessak подарок для настоящег...  \n",
       "97     Как заменить привычные чипсы? Отведайте сушки ...  \n",
       "102    Меня просто спровоцировали а те кто пишет в мо...  \n",
       "104    AMC FNG Амиржанов Гаджимурад Денисов Сергей 23...  \n",
       "...                                                  ...  \n",
       "38665  Они опять в Таиланде Кто помнит предыдущие фот...  \n",
       "38683  Дана Уайт сообщил когда и с кем будет драться ...  \n",
       "38689  Генри Сехудо считает что Хамзат Чимаев эмоцион...  \n",
       "38691  Детский набор для творчества с мольбертом 176 ...  \n",
       "38728  ️Рамазан Гасанов 8 0 побеждает Насимжона Шарип...  \n",
       "\n",
       "[3050 rows x 3 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['category'] == 'martial_arts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fe98874e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/nikita.boyarskikh/.cache/huggingface/hub/models--DeepPavlov--rubert-base-cased-conversational/snapshots/645946ce91842a52eaacb2705c77e59194145ffa/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"DeepPavlov/rubert-base-cased-conversational\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /Users/nikita.boyarskikh/.cache/huggingface/hub/models--DeepPavlov--rubert-base-cased-conversational/snapshots/645946ce91842a52eaacb2705c77e59194145ffa/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /Users/nikita.boyarskikh/.cache/huggingface/hub/models--DeepPavlov--rubert-base-cased-conversational/snapshots/645946ce91842a52eaacb2705c77e59194145ffa/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /Users/nikita.boyarskikh/.cache/huggingface/hub/models--DeepPavlov--rubert-base-cased-conversational/snapshots/645946ce91842a52eaacb2705c77e59194145ffa/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/nikita.boyarskikh/.cache/huggingface/hub/models--DeepPavlov--rubert-base-cased-conversational/snapshots/645946ce91842a52eaacb2705c77e59194145ffa/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"DeepPavlov/rubert-base-cased-conversational\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/nikita.boyarskikh/.cache/huggingface/hub/models--DeepPavlov--rubert-base-cased-conversational/snapshots/645946ce91842a52eaacb2705c77e59194145ffa/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"DeepPavlov/rubert-base-cased-conversational\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/nikita.boyarskikh/.cache/huggingface/hub/models--DeepPavlov--rubert-base-cased-conversational/snapshots/645946ce91842a52eaacb2705c77e59194145ffa/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"DeepPavlov/rubert-base-cased-conversational\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /Users/nikita.boyarskikh/.cache/huggingface/hub/models--DeepPavlov--rubert-base-cased-conversational/snapshots/645946ce91842a52eaacb2705c77e59194145ffa/pytorch_model.bin\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8431fcd901843688ba06efea0648e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38740 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('DeepPavlov/rubert-base-cased-conversational', use_fast=True)\n",
    "model = AutoModel.from_pretrained('DeepPavlov/rubert-base-cased-conversational', num_labels=len(LABELS))\n",
    "\n",
    "def preprocess_function(data):\n",
    "    return tokenizer(data['text'], data['category'], max_length=512, truncation=True)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train_data['text'], train_data['category'], test_size=0.2, random_state=42)\n",
    "encoded_dataset = Dataset.from_pandas(train_data).map(preprocess_function)\n",
    "small_train_dataset = encoded_dataset.shuffle(seed=42).select(range(1000))\n",
    "small_test_dataset = encoded_dataset.shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ca74a60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 100\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 100\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 50\n",
      "  Number of trainable parameters = 177853440\n",
      "The following columns in the training set don't have a corresponding argument in `BertModel.forward` and have been ignored: category, oid, text. If category, oid, text are not expected by `BertModel.forward`,  you can safely ignore this message.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The model did not return a loss from the inputs, only the following keys: last_hidden_state,pooler_output. For reference, the inputs it received are input_ids,token_type_ids,attention_mask.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [135], line 29\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m classification_report(predictions[:, \u001b[38;5;241m0\u001b[39m], labels)\n\u001b[1;32m     21\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     22\u001b[0m     model,\n\u001b[1;32m     23\u001b[0m     args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[1;32m     28\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/trainer.py:1527\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1524\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1526\u001b[0m )\n\u001b[0;32m-> 1527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/trainer.py:1775\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1773\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1778\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1780\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/trainer.py:2523\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2523\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2526\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/trainer.py:2568\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2566\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[0;32m-> 2568\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model did not return a loss from the inputs, only the following keys: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2570\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(outputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. For reference, the inputs it received are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2571\u001b[0m         )\n\u001b[1;32m   2572\u001b[0m     \u001b[38;5;66;03m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[39;00m\n\u001b[1;32m   2573\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: last_hidden_state,pooler_output. For reference, the inputs it received are input_ids,token_type_ids,attention_mask."
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "metric_name = 'cross-entropy'\n",
    "args = TrainingArguments(\n",
    "    f\"rubert-base-cased-conversational-finetuned\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    return {\n",
    "        metric_name: classification_report(predictions[:, 0], labels),\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb50e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = trainer.hyperparameter_search(n_trials=10, direction=\"maximize\")\n",
    "best_run.hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a4162db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;sgd_clf&#x27;, SGDClassifier(loss=&#x27;log_loss&#x27;, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;sgd_clf&#x27;, SGDClassifier(loss=&#x27;log_loss&#x27;, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(loss=&#x27;log_loss&#x27;, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('sgd_clf', SGDClassifier(loss='log_loss', random_state=42))])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "sgd_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('sgd_clf', SGDClassifier(random_state=42, loss='log_loss')),\n",
    "])\n",
    "knb_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('knb_clf', KNeighborsClassifier(n_neighbors=10)),\n",
    "])\n",
    "sgd_clf.fit(train_data['text'], train_data['category'])\n",
    "# print(classification_report(predicted_sgd, train_data['category'][0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9fc5936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_sgd = sgd_clf.predict(test_data['text'][0:10])\n",
    "# for text, label in zip(test_data['text'][0:10], predicted_sgd):\n",
    "#     print(text)\n",
    "#     print(label)\n",
    "#     print()\n",
    "predicted_sgd_proba = sgd_clf.predict_proba(test_data['text'])\n",
    "predicted_sgd = sgd_clf.predict(test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "738951e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test_data.copy()\n",
    "res['predicted_sgd'] = predicted_sgd\n",
    "res['sgd_proba'] = predicted_sgd_proba.max(axis=1)\n",
    "res = res.sort_values('sgd_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0eb47854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athletics \t Бег мотивация 33 Смотри вдохнавляйся беги 33 rtokenoid бег спорт забег всембег rtokenoid parkrtokenoid sport легкаяАтлетика\n",
      "athletics \t Как улучшить бег? Увеличте скорость 33 rtokenoid легкаяАтлетика спорт забег зож rtokenoid\n",
      "athletics \t Всем бег и легких ног 33 Бегите на позитиве друзья 33 rtokenoid rtokenoid бег легкаяАтлетика спорт всембег забегРФ забег rtokenoid\n",
      "athletics \t Всем бег и легких ног rtokenoid rtokenoid спорт мотивация бег забег пробежка бегун всембег беганутые\n",
      "athletics \t БЕГ ЭТО РАДОСТЬ Беги на позитиве 33. . rtokenoid. . . . . rtokenoid rtokenoid parkrtokenoid бег спорт забег всембег наспорте беганутые ла легкаяАтлетика\n",
      "athletics \t ‍ ️ ‍ ️Всем бег и легких ног друзья rtokenoid rtokenoid rtokenoid бег марафон марафонец забег забегРФ спорт атлет\n",
      "athletics \t А кто ты на светофоре? rtokenoid rtokenoid бег спорт забег марафон марафонец зож наспорте легкаяАтлетика\n",
      "athletics \t ‍ ️ ‍ ️Всем бег и легких ног rtokenoid rtokenoid rtokenoid бег легкаяАтлетика спорт зож беганутые марафонец\n",
      "athletics \t Всем бег и легких ног 33. . . rtokenoid. . . . . . . rtokenoid бег спорт ла легкаяАтлетика марафон марафонец бег зож забег\n",
      "athletics \t Всем бег и легких ног 33. . . rtokenoid. . . . . . . rtokenoid бег спорт ла легкаяАтлетика марафон марафонец бег зож забег\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fl/ys8k2g5s0sdfvq58n15mnjdr0000gq/T/ipykernel_89018/1655474595.py:1: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  for text, cat in zip(res['text'][-10:], res['predicted_sgd'][-10:]):\n"
     ]
    }
   ],
   "source": [
    "for text, cat in zip(res['text'][-10:], res['predicted_sgd'][-10:]):\n",
    "    print(cat, '\\t', text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
